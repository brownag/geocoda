---
title: "Advanced Data Preparation: Gap Filling & Integration"
author: "Andrew G. Brown"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Data Preparation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  dpi = 100
)
```

# Overview

Before geostatistical simulation, soil data requires careful preparation. This vignette addresses practical challenges:

- **Sparse data**: Few observations for variogram fitting
- **Edge effects**: Boundary artifacts in predictions
- **Zero values**: Non-detected components or trace elements
- **Multi-source data**: Field observations + SSURGO with different quality
- **Depth variation**: Compositional changes with depth

These issues can destabilize variogram estimates and degrade predictions. Proper preparation improves model reliability.

# Setting Up

```{r, message=FALSE}
library(geocoda)
library(terra)
library(sf)
library(gstat)
library(compositions)

set.seed(42)
```

# Handling Sparse Data

## Bootstrap Resampling

When observations are few (<10), variogram estimation becomes unstable. **Bootstrap resampling** expands the effective sample size by generating plausible compositional variants at observed locations:

```{r sparse_data}
# Sparse field observations
sparse_obs <- data.frame(
  x = c(10, 30, 50, 70, 90),
  y = c(20, 40, 60, 80, 85),
  SAND = c(55, 48, 35, 42, 60),
  SILT = c(30, 38, 45, 40, 25),
  CLAY = c(15, 14, 20, 18, 15)
)

cat("Original samples:", nrow(sparse_obs), "\n")

# Expand from 5 to 30 samples via resampling
resampled <- gc_resample_compositions(
  composition_grid = sparse_obs[, c("SAND", "SILT", "CLAY")],
  n = 30,
  method = "uniform"
)

cat("Resampled:", nrow(resampled$samples), "\n")

# Replicate spatial coordinates
expanded_spatial <- do.call(
  rbind,
  replicate(6, sparse_obs, simplify = FALSE)
)
expanded_spatial$SAND <- as.numeric(resampled$samples[, "SAND"])
expanded_spatial$SILT <- as.numeric(resampled$samples[, "SILT"])
expanded_spatial$CLAY <- as.numeric(resampled$samples[, "CLAY"])

cat("Expanded dataset:", nrow(expanded_spatial), "samples\n")
```

**Key concept**: Resampling preserves compositional structure while adding spatial replication for better variogram stability. The spatial coordinates are duplicated; uncertainty comes from compositional variation, not location.

## Edge Extension

Edge effects occur where predictions are far from data. **Edge extension** adds mirrored samples beyond boundaries:

```{r edge_extension}
extend_at_edges <- function(data, extend_factor = 0.2) {
  x_range <- diff(range(data$x))
  y_range <- diff(range(data$y))
  extend_x <- extend_factor * x_range
  extend_y <- extend_factor * y_range

  # Mirror samples beyond each edge
  extended_left <- data.frame(
    x = data$x - 2 * extend_x, y = data$y,
    data[, c("SAND", "SILT", "CLAY")]
  )
  extended_right <- data.frame(
    x = data$x + 2 * extend_x, y = data$y,
    data[, c("SAND", "SILT", "CLAY")]
  )
  extended_bottom <- data.frame(
    x = data$x, y = data$y - 2 * extend_y,
    data[, c("SAND", "SILT", "CLAY")]
  )
  extended_top <- data.frame(
    x = data$x, y = data$y + 2 * extend_y,
    data[, c("SAND", "SILT", "CLAY")]
  )

  rbind(data[, c("x", "y", "SAND", "SILT", "CLAY")],
        extended_left, extended_right,
        extended_bottom, extended_top)
}

extended <- extend_at_edges(expanded_spatial, extend_factor = 0.25)
cat("Extended dataset:", nrow(extended), "samples\n")
```

**When to use**: For prediction grids that extend to domain edges. Edge extension reduces kriging variance at boundaries.

# Handling Zero Values

## Zero Imputation Strategies

Real-world compositional data often contains zeros (non-detected values, trace components). Zeros are problematic because geometric means are undefined.

```{r zeros}
data_with_zeros <- data.frame(
  x = c(1, 2, 3, 4, 5),
  y = c(1, 2, 3, 4, 5),
  SAND = c(50, 48, 0, 42, 60),
  SILT = c(30, 38, 0, 40, 25),
  CLAY = c(20, 14, 100, 18, 15)
)

# Impute zeros using multiplicative replacement
handled_zeros <- gc_handle_zeros(
  comp_data = data_with_zeros[, c("SAND", "SILT", "CLAY")],
  dl = 0.5,
  method = "mzero"
)

cat("Imputation rate:", handled_zeros$imputation_rate, "\n")
cat("Rows imputed:\n")
print(head(handled_zeros$imputed_data))
```

**Methods**:
- **mzero** (multiplicative): Fast, replaces zeros with small multiple of detection limit
- **azero** (additive): Conservative, adds small constant to all values
- **lrem** (log-ratio EM): Probabilistic, uses expectation-maximization

For soil texture (<5% zeros), `mzero` is sufficient. For many zeros (>30%), use `lrem`.

# Multi-Source Data Integration

## Weighting Components by Source Quality

Combine field observations with SSURGO data, weighting by reliability:

```{r multi_source}
# Field observations (higher weight)
field_obs <- data.frame(
  x = c(10, 30, 50, 70, 90),
  y = c(20, 40, 60, 80, 85),
  depth_cm = 10,
  SAND = c(55, 48, 35, 42, 60),
  SILT = c(30, 38, 45, 40, 25),
  CLAY = c(15, 14, 20, 18, 15),
  weight = 1.0,
  source = "field"
)

# SSURGO estimates (lower weight, larger uncertainty)
ssurgo_data <- data.frame(
  x = c(20, 40, 60, 80),
  y = c(30, 50, 70, 90),
  depth_cm = 10,
  SAND = c(50, 45, 38, 40),
  SILT = c(35, 40, 42, 38),
  CLAY = c(15, 15, 20, 22),
  weight = 0.5,
  source = "ssurgo"
)

combined_data <- rbind(field_obs, ssurgo_data)

# Weight components by source reliability
weight_components <- function(data) {
  # Apply weights: field gets higher multiplier than SSURGO
  data$SAND_w <- data$SAND * ifelse(data$source == "field", 1.0, 0.7)
  data$SILT_w <- data$SILT * ifelse(data$source == "field", 1.0, 0.7)
  data$CLAY_w <- data$CLAY * ifelse(data$source == "field", 1.0, 0.5)

  # Renormalize to 100%
  total_w <- data$SAND_w + data$SILT_w + data$CLAY_w
  data$SAND_wt <- (data$SAND_w / total_w) * 100
  data$SILT_wt <- (data$SILT_w / total_w) * 100
  data$CLAY_wt <- (data$CLAY_w / total_w) * 100

  return(data)
}

weighted_data <- weight_components(combined_data)

# Compare before/after weighting
cat("Field SAND - Field:\n")
print(weighted_data$SAND[1])
cat("SSURGO SAND - Original vs Weighted:\n")
print(c(original = weighted_data$SAND[6],
        weighted = weighted_data$SAND_wt[6]))
```

**Key principle**: Higher-quality data (field measurements) pull the weighted composition toward their values. SSURGO data acts as a prior, stabilizing estimates in data-sparse areas.

# Depth Stratification

## Handling Compositional Changes with Depth

Soil texture often varies with depth. Model each depth interval separately:

```{r depth_strat}
# Data with two depths
surface_obs <- data.frame(
  x = c(10, 30, 50),
  y = c(20, 40, 60),
  depth = "0-30cm",
  SAND = c(60, 55, 50),
  SILT = c(25, 30, 35),
  CLAY = c(15, 15, 15)
)

subsurface_obs <- data.frame(
  x = c(10, 30, 50),
  y = c(20, 40, 60),
  depth = "30-60cm",
  SAND = c(40, 38, 32),
  SILT = c(35, 38, 42),
  CLAY = c(25, 24, 26)
)

all_depth_data <- rbind(surface_obs, subsurface_obs)

# Summarize by depth
cat("Surface (0-30cm) - Mean composition:\n")
print(colMeans(surface_obs[, c("SAND", "SILT", "CLAY")]))

cat("\nSubsurface (30-60cm) - Mean composition:\n")
print(colMeans(subsurface_obs[, c("SAND", "SILT", "CLAY")]))

cat("\nNote: Surface has more sand and less clay (weathering)")
cat("\nSubsurface has more clay (accumulation)\n")
```

**Workflow**: Prepare separate models for each depth interval, then simulate independently. Combine results post-simulation for 3D products.

# Practical Data Validation Checklist

Before proceeding to variogram fitting:

```{r validation_checklist}
validation_checklist <- data.frame(
  Check = c(
    "Compositional sum",
    "Non-negative values",
    "Realistic ranges",
    "Spatial coverage",
    "Sample size",
    "Outliers",
    "Zero handling"
  ),
  Status = c(
    "All rows sum to 100%?",
    "All components >= 0%?",
    "Domain knowledge satisfied?",
    "Good coverage or gaps?",
    ">5 samples per zone?",
    "Check for extreme values",
    "Handled appropriately?"
  )
)

print(validation_checklist)
```

# Integration with Variogram Fitting

After data preparation, proceed to variogram fitting:

```{r vgm_workflow, eval=FALSE}
# After applying preparations above:
# 1. Prepare cleaned, weighted, depth-stratified data
# 2. Estimate ILR parameters
ilr_params <- gc_ilr_params(weighted_data[, c("SAND_wt", "SILT_wt", "CLAY_wt")])

# 3. Transform to ILR space for variogram fitting
obs_ilr <- compositions::ilr(
  compositions::acomp(weighted_data[, c("SAND_wt", "SILT_wt", "CLAY_wt")])
)

# 4. Fit variogram with prepared data
vgm_data <- data.frame(
  x = weighted_data$x,
  y = weighted_data$y,
  ilr1 = obs_ilr[, 1],
  ilr2 = obs_ilr[, 2]
)

vgm_fitted <- gc_fit_vgm(ilr_params, data = vgm_data, aggregate = TRUE)

# 5. Proceed with simulation as in Complete Workflow vignette
```

# Best Practices Summary

- **Sparse data** → Use bootstrap resampling + edge extension
- **Edge predictions** → Always apply edge extension
- **Zero values** → Use mzero for <5% zeros, lrem for >30%
- **Multi-source** → Weight by data quality and measurement uncertainty
- **Depth variation** → Model each depth interval separately
- **Validate first** → Check compositionality, ranges, coverage before proceeding

For the complete workflow including these preparations, see Vignette 00: Complete Soil Mapping Workflow.

# References

- Aitchison, J. (1986). *The Statistical Analysis of Compositional Data*. Chapman and Hall, London.
- van den Boogaart, K. G., & Tolosana-Delgado, R. (2008). "compositions": A unified R package to analyze compositional data. *Computers & Geosciences*, 34(4), 320-338.
