---
title: "Hierarchical Model Backends: Deep Dive"
author: "Andrew G. Brown"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Hierarchical Backends Deep Dive}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  dpi = 100
)
```

# Overview

Technical deep dive into the three hierarchical model backends available in geocoda:

1. **Analytical (Empirical Bayes)** - Fast, deterministic shrinkage estimation
2. **Stan (HMC)** - Full Bayesian inference with Hamiltonian Monte Carlo
3. **Nimble (MCMC)** - Adaptive MCMC with flexible model specification

This vignette provides mathematical foundations, implementation details, and guidance for developers extending these backends.

## Vignette Status

**Minimal scaffold** - Will be expanded with:
- Detailed mathematical derivations
- Backend implementation architecture
- MCMC sampler configuration
- Convergence diagnostics deep dive
- Debugging and optimization strategies
- Benchmarking comparisons

# Analytical Backend: Empirical Bayes

## Mathematical Foundations

```{r analytical_math, eval=FALSE}
# COMING: Detailed analytical backend mathematics

# Hierarchical model structure:
# Observation level: y_n ~ N(μ_z[n], Σ)
# Zone level: μ_z ~ N(μ_global, τ_pooling² I)
# Global level: μ_global ~ N(μ_prior, σ_prior² I)

# Empirical Bayes shrinkage:
# τ_pooling² estimated from data (profile likelihood)
# Zone estimates shrunk toward global mean
# Shrinkage weight: w_z = n_z / (n_z + τ_pooling²)

# Final estimate: μ_z^* = w_z * μ_z + (1 - w_z) * μ_global
```

## Implementation Details

```{r analytical_implementation, eval=FALSE}
# COMING: Analytical backend implementation details

# Computational approach:
# 1. Compute zone-specific MLE estimates
# 2. Estimate global hyperparameters
# 3. Profile likelihood for pooling coefficient
# 4. Apply shrinkage formula to all zones
# 5. Compute uncertainty intervals via bootstrap/delta method

# Complexity: O(Z * D²) where Z = zones, D = dimensions
# Runtime: seconds for typical problems
```

## Limitations & Strengths

```{r analytical_comparison, eval=FALSE}
# COMING: When analytical backend is appropriate

# Strengths:
# ✓ Very fast (seconds)
# ✓ No tuning required
# ✓ Deterministic (reproducible)
# ✓ Good for initial exploration

# Limitations:
# ✗ Point estimates only (no posterior samples)
# ✗ Assumes known pooling structure
# ✗ No posterior predictive simulation
# ✗ Limited for complex structures
```

# Stan Backend: HMC Sampling

## Mathematical Foundations

```{r stan_math, eval=FALSE}
# COMING: Stan backend mathematics

# Probabilistic model in Stan:
# y_n ~ Normal(μ_z[zone[n]], Σ)
# μ_z[z] ~ Normal(μ_global, τ_pooling * L @ L')  [MVN via Cholesky]
# μ_global ~ Normal(μ_prior, σ_prior)
# τ_pooling ~ Exponential(rate) [optional]
# L ~ LKJ(eta) [correlation, LKJ prior]
# sigma ~ Exponential(rate) [marginal SDs]

# Inference: Hamiltonian Monte Carlo (HMC) with NUTS sampler
# Gradient computation: Automatic differentiation
# Warmup: Adaptation of step size and metric
# Sampling: Leapfrog integrator with log-probability gradient
```

## Stan Model Structure

```{r stan_model, eval=FALSE}
# COMING: Detailed Stan model code and specification

# Key features in geocoda's Stan model:
# - Conditional blocks for fixed vs estimated pooling
# - LKJ + variance decomposition for flexible priors
# - Efficient parameterization (non-centered)
# - Vectorized likelihood for speed
```

## MCMC Configuration

```{r stan_config, eval=FALSE}
# COMING: Stan MCMC tuning and diagnostics

# Default configuration:
# - Chains: 2 parallel HMC chains
# - Iterations: 2000 per chain
# - Warmup: 500 iterations (adaptation phase)
# - adapt_delta: 0.8 (step size adaptation)
# - max_treedepth: 10 (NUTS trajectory limit)

# Advanced tuning options:
# - Reparameterization (non-centered vs centered)
# - Custom priors for specific parameters
# - Initialization strategies for difficult problems
```

## Convergence Diagnostics

```{r stan_diagnostics, eval=FALSE}
# COMING: Stan convergence diagnostics guide

# Key diagnostics:
# - Rhat (potential scale reduction factor): < 1.1 indicates convergence
# - Effective Sample Size (ESS): > 100 per parameter (minimum)
# - Divergent transitions: Should be 0 or very few
# - Tree depth: Should not hit max_treedepth frequently
# - Energy: Plot should show good mixing

# Troubleshooting:
# - Rhat > 1.1: Increase iterations, check model specification
# - ESS < 100: Increase iterations, consider reparameterization
# - Many divergences: Increase adapt_delta or reparameterize
```

# Nimble Backend: Adaptive MCMC

## Mathematical Foundations

```{r nimble_math, eval=FALSE}
# COMING: Nimble backend mathematics

# Probabilistic model in Nimble (R-like syntax):
# Same hierarchical structure as Stan
# Inference: Adaptive Metropolis-Hastings MCMC
# Samplers: Block sampling for multivariate parameters
# Adaptation: Adaptive proposal scaling
```

## Nimble Model Specification

```{r nimble_model, eval=FALSE}
# COMING: Nimble model code and configuration

# R-like model specification with nimbleCode()
# Automatically configures samplers with configureMCMC()
# Custom samplers for multivariate parameters
# Efficient compilation via C++
```

## MCMC Configuration

```{r nimble_config, eval=FALSE}
# COMING: Nimble sampler configuration

# Default sampler setup:
# - Univariate: slice sampler or random walk
# - Multivariate: block Metropolis-Hastings
# - Adaptive scaling: Adaptation period then fixed
# - Parallel chains: Chain management and combining

# Advanced options:
# - Custom sampler replacement
# - Tuning parameter optimization
# - Multiple parameterizations
```

## Convergence Diagnostics

```{r nimble_diagnostics, eval=FALSE}
# COMING: Nimble convergence diagnostics

# Diagnostics available:
# - Gelman-Rubin (multivariate potential scale reduction)
# - Univariate and multivariate trace plots
# - Autocorrelation function analysis
# - Effective sample size via coda package

# Troubleshooting:
# - Chains not mixing: Adjust proposal scaling
# - High autocorrelation: Increase lag in samplers
# - Non-convergence: Check model specification
```

# Backend Comparison

## Computational Characteristics

```{r backend_comparison, eval=FALSE}
# COMING: Comprehensive backend comparison

# Comparison table:
# | Feature | Analytical | Stan | Nimble |
# |---------|-----------|------|--------|
# | Speed | Very fast | Slow | Medium |
# | Flexibility | Low | Medium | High |
# | Diagnostics | None | Excellent | Good |
# | Posterior samples | No | Yes | Yes |
# | Parallelization | N/A | Auto | Manual |
# | Learning curve | Easy | Medium | Medium |
```

## Decision Framework

```{r backend_decision, eval=FALSE}
# COMING: When to use each backend

# Use ANALYTICAL if:
# - Quick initial exploration needed
# - Fixed pooling structure known
# - Point estimates sufficient
# - Performance critical

# Use STAN if:
# - Full Bayesian inference desired
# - Convergence diagnostics needed
# - Complex hierarchical structures
# - Parallelizable workstations available

# Use NIMBLE if:
# - Maximum model flexibility needed
# - Custom sampler configuration required
# - Difficult posterior landscapes
# - Research/prototyping phase
```

# Advanced Topics

## Custom Prior Specification

```{r custom_priors, eval=FALSE}
# COMING: Specifying custom priors for MCMC backends

# Prior components:
# - Global mean priors
# - Pooling coefficient priors
# - Covariance structure priors (LKJ vs Inverse-Wishart)
# - Marginal variance priors

# Weakly informative vs strongly informative
# Sensitivity analysis for prior impact
```

## Model Extensions

```{r model_extensions, eval=FALSE}
# COMING: Extending backends for specialized models

# Possible extensions:
# - Missing data imputation (Stan & Nimble)
# - Non-compositional multivariate data
# - Spatial correlation between zones
# - Time-varying parameters
```

# Performance Benchmarking

```{r benchmarking, eval=FALSE}
# COMING: Backend performance benchmarks

# Benchmark scenarios:
# - Small problem (3 zones, 5 samples/zone)
# - Medium problem (10 zones, 30 samples/zone)
# - Large problem (50 zones, 100 samples/zone)

# Metrics:
# - Runtime (seconds/minutes)
# - Memory usage (MB)
# - Posterior quality
# - Convergence rate
```

# Integration with geocoda Workflow

## Using Backends in Analysis

```{r workflow_integration, eval=FALSE}
# COMING: Practical integration examples

# Typical workflow:
# 1. Start with analytical backend (fast, exploratory)
# 2. If posterior uncertainty needed, switch to Stan or Nimble
# 3. Check convergence diagnostics
# 4. Extract posterior samples for downstream analysis
# 5. Proceed with simulation using posterior mean or samples
```

# References

- Stan Development Team. Stan User's Guide.
- Nimble Project. NIMBLE User Manual.
- Gelman et al. (2013). Bayesian Data Analysis, 3rd edition.

---

**This deep dive will be expanded with:**
- Complete mathematical derivations
- Full source code and implementation details
- Convergence diagnosis procedures
- Performance benchmarking results
- Troubleshooting guides for each backend
- Advanced customization examples
